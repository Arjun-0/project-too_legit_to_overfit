---
title: "Project proposal"
author: "Too Legit to Overfit"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r load-packages, message = FALSE}
library(tidyverse)
library(broom)
library(pander)
library(here)
```

```{r load-data, message = FALSE}
board_games <- read_csv(here("data/board_games.csv"))
```

## 1. Introduction

The dataset we are looking at is a collection of board games from Board Game Geeks, which is a crowd-sourced board game review platform.

We would like to use this dataset to analyze the factors that will affect the rating of a board game. We will be looking at `year_published`, `category`, `playing_time`, and `users_rated` in relation to `average_rating`.

## 2. Data

```{r dimensions}
glimpse(board_games)
```


## 3. Data analysis plan

Our predictor variables will be `year_published`, `category`, `playing_time`, and `users_rated`. Our response variable will be `average_rating`.


We will try to look for correlations between category and popularity, number of ratings, and playtime. The most common categories are:

```{r popular-categories}
board_games_splitcats <- board_games %>% 
  mutate(categories = str_split(category, ","))

popular_categories <- board_games_splitcats %>%
  pull(categories) %>%
  unlist %>%
  as_tibble %>%
  count(value) %>%
  arrange(desc(n)) %>%
  head(6)

popular_categories %>%
  pander

popular_categories <- pull(popular_categories, value)
```

```{r filter-top-cats-alt}
board_games_topcats <- board_games_splitcats %>% 
  filter(map_lgl(categories, ~any(popular_categories %in% .x)))
```

We can investigate the changes in quality of different categories of games. For example, investigating how the quality of board games in the six most common categories changes over time. As a measure of quality, we use the mean rating given to a game in that category (that is, the sum of all ratings in a category (in a given year) divided by the total number of such ratings). 

```{r top-cats-over-time, message = FALSE, warning = FALSE}
av_annual_rating <- function(df, cat = NULL) {
  {if(!is.null(cat)) {
    df %>% filter(map_lgl(categories, ~cat %in% .x))
  } else {
    df
  }} %>% 
  group_by(year_published) %>% 
  summarise(av_annual_rating = sum(average_rating * users_rated) / sum(users_rated))
}
# finds average rating (of a category (cat) if given) of board games in dataframe given (df) for each year in which a board game of that category was published. Output is a dataframe. df must have columns `year published`, `categories` (a `list` of categories), `average_rating` and `year_published`. 

cats <- map(popular_categories, ~av_annual_rating(df = board_games_topcats, cat = .))

cat_ratings <- reduce(cats, ~full_join(.x,.y, by = "year_published")) %>% 
  arrange(year_published)

if(any(is.na(popular_categories))) {
  popular_categories[[which(is.na(popular_categories))]] <- "not_categorised"
} 

names(cat_ratings) <- c("year_published", popular_categories)
```

```{r top-cats-over-time-plot, warning = FALSE}
cat_ratings %>% 
  pivot_longer(cols = 2:ncol(cat_ratings), names_to = "category", values_to = "av_rating") %>% 
  ggplot(aes(x = year_published, y = av_rating, colour = category)) + 
  geom_line() + 
  labs(
    x = "Year published", 
    y = "Mean annual category rating", 
    colour = "Category", 
    title = "Average ratings of the 6 most popular game categories by year published"
  ) + 
  scale_color_viridis_d() +
  theme_minimal()
```

This plot indicates a fairly strong association between mean ratings (of games in the six most popular categories) and time. That is, more recent games (regardless of category) are rated more highly on average than older games. We can investigate further whether this is something universal across all categories, and whether any other variables such as changes in playtime or game mechanics, for example, could be an influence. 

```{r total-ratings-over-time, message = FALSE}
board_games_splitcats %>% 
  av_annual_rating() %>% 
  ggplot(aes(x = year_published, y = av_annual_rating)) +
  geom_line() +
  labs(
    x = "Year published",
    y = "Mean annual rating",
    title = "Average ratings of board games by year published"
  ) +
  scale_color_viridis_d() +
  theme_minimal()
```

Indeed the overall trend for board game ratings has been an increase in ratings for more recently published games. 

```{r rating-v-playtime, warning = FALSE}
board_games_splitcats %>% 
  mutate(
    top_games = if_else(
      rank(desc(board_games_splitcats$average_rating))<=100, 
      "In top 100", 
      "Not in top 100"
    )
  ) %>% 
ggplot() + 
  geom_boxplot(mapping = aes(playing_time, top_games)) + 
  xlim(NA, 200) + 
  labs(
    x = "Average playing time in minutes",
    y = "Subset",
    title = "Distribution of game playing time"
  ) +
  theme_minimal()
```

As seen in the boxplots, games that are more highly rated tend to have a longer playing time. 

Plotting the number of ratings against the average rating of each game: 

```{r no_ratings-v-rating, warning = FALSE}
board_games_splitcats %>%
 ggplot() +
 geom_point(aes(x = users_rated, y = average_rating), alpha = 0.5) +
 labs(
 x = "Number of ratings",
 y = "Average ratings",
 title = "Number of ratings against average rating"
 )
```

This plot suggests that games with more ratings tend to have an average rating closer to just under 7.5. However, this may be because there are more games with a rating of 7.5, which increases the likelihood that there will be a game with particularly a large number of ratings. To analyze this further, we will need to eliminate the effect of this confounding variable (number of games with a given rating) to properly analyze the relationship between the two variables. 


Hypothesis:

Category has an effect on the average rating, the year published and the playing time have a positive association with the average rating, and as the number of individual ratings rises the average rating tends towards 7.5.

In order to reach our conclusions we will need to model each individual variable against the average rating and use statistical tests such as the chi-squared test to evaluate the fit of each model. We will also use correlation coefficient tests to investigate the strength of linear relationships. We will use modeling to eliminate the influence of the distribution of the average ratings on our graph plotting the number of ratings against the average ratings.